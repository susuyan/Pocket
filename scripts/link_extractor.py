#!/usr/bin/env python3
"""
ç»Ÿä¸€é“¾æŽ¥æå–å™¨ (Universal Link Extractor)
åŠŸèƒ½ï¼šè‡ªåŠ¨è¯†åˆ«é“¾æŽ¥ç±»åž‹ï¼ˆWeibo/Twitter/Xï¼‰ï¼Œå¹¶è°ƒç”¨ç›¸åº”çš„æå–å™¨èŽ·å–å†…å®¹ã€‚
"""

import sys
import argparse
import re
from typing import Optional
from urllib.parse import urlparse

# å°è¯•å¯¼å…¥åŒç›®å½•ä¸‹çš„æå–å™¨
try:
    from weibo_extractor import WeiboExtractor
    from twitter_extractor import TwitterExtractor
except ImportError:
    # å¦‚æžœä½œä¸ºæ¨¡å—è¿è¡Œå¯èƒ½éœ€è¦è°ƒæ•´è·¯å¾„
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from weibo_extractor import WeiboExtractor
    from twitter_extractor import TwitterExtractor

class LinkExtractor:
    def __init__(self, proxy: Optional[str] = None):
        self.weibo_extractor = WeiboExtractor()
        self.twitter_extractor = TwitterExtractor(proxy=proxy)
        
    def extract(self, url: str) -> str:
        """æ ¹æ® URL è‡ªåŠ¨åˆ†å‘åˆ°å¯¹åº”çš„æå–å™¨"""
        domain = urlparse(url).netloc
        
        if any(x in domain for x in ['weibo.com', 'weibo.cn']):
            return self._extract_weibo(url)
        elif any(x in domain for x in ['twitter.com', 'x.com']):
            return self._extract_twitter(url)
        else:
            return f"âŒ ä¸æ”¯æŒçš„é“¾æŽ¥åŸŸå: {domain}\nç›®å‰ä»…æ”¯æŒ: weibo.com, weibo.cn, twitter.com, x.com"

    def _extract_weibo(self, url: str) -> str:
        print(f"ðŸ” æ£€æµ‹åˆ°å¾®åšé“¾æŽ¥: {url}")
        post = self.weibo_extractor.extract(url)
        if post:
            # é»˜è®¤ä½¿ç”¨ Markdown æ ¼å¼
            return post.format_output('markdown')
        return "âŒ å¾®åšæå–å¤±è´¥"

    def _extract_twitter(self, url: str) -> str:
        print(f"ðŸ” æ£€æµ‹åˆ° Twitter/X é“¾æŽ¥: {url}")
        data = self.twitter_extractor.extract(url)
        if data:
            return self.twitter_extractor.format_output(data)
        return "âŒ Twitter æå–å¤±è´¥ (è¯·æ£€æŸ¥ç½‘ç»œæˆ–ä»£ç†)"

def main():
    parser = argparse.ArgumentParser(
        description='ç»Ÿä¸€é“¾æŽ¥æå–å™¨ - è‡ªåŠ¨è¯†åˆ« Weibo/Twitter é“¾æŽ¥å¹¶æå–å†…å®¹',
        epilog='ç¤ºä¾‹: python link_extractor.py https://x.com/user/status/123'
    )
    parser.add_argument('urls', nargs='+', help='ä¸€ä¸ªæˆ–å¤šä¸ªé“¾æŽ¥')
    parser.add_argument('-p', '--proxy', help='æŒ‡å®šä»£ç† (ä»…å¯¹ Twitter æœ‰æ•ˆï¼ŒWeibo ç›´è¿ž)')
    
    args = parser.parse_args()
    
    extractor = LinkExtractor(proxy=args.proxy)
    
    for i, url in enumerate(args.urls):
        if i > 0:
            print("\n" + "-"*50 + "\n")
        print(extractor.extract(url))

if __name__ == '__main__':
    main()
